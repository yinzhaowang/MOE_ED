{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "employed-shirt",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import shap\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cognitive-princeton",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Expert(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, output_size, p_dropout=0.3):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        prev = input_size\n",
    "        for h in hidden_sizes:\n",
    "            layers += [nn.Linear(prev, h), nn.ReLU(), nn.Dropout(p_dropout)]\n",
    "            prev = h\n",
    "        layers.append(nn.Linear(prev, output_size))\n",
    "        self.net = nn.Sequential(*layers)\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class Tower(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, p_dropout=0.4):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p_dropout),\n",
    "            nn.Linear(hidden_size, output_size)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class MMoE(nn.Module):\n",
    "    def __init__(self, input_size, num_experts, expert_hidden, expert_output_dim, tower_hidden_dim, task_output_dims):\n",
    "        super().__init__()\n",
    "        self.num_tasks = len(task_output_dims)\n",
    "        self.experts = nn.ModuleList(\n",
    "            Expert(input_size, expert_hidden, expert_output_dim)\n",
    "            for _ in range(num_experts)\n",
    "        )\n",
    "        self.gates = nn.ModuleList(\n",
    "            nn.Linear(input_size, num_experts, bias=False)\n",
    "            for _ in range(self.num_tasks)\n",
    "        )\n",
    "        self.towers = nn.ModuleList(\n",
    "            Tower(expert_output_dim, tower_hidden_dim, out_dim)\n",
    "            for out_dim in task_output_dims\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        expert_stack = torch.stack([expert(x) for expert in self.experts], dim=0)\n",
    "        outputs = []\n",
    "        for gate, tower in zip(self.gates, self.towers):\n",
    "            weights = F.softmax(gate(x), dim=1)\n",
    "            weighted = torch.einsum(\"be,ebd->bd\", weights, expert_stack)\n",
    "            y = tower(weighted)\n",
    "            outputs.append(y)\n",
    "        return outputs\n",
    "\n",
    "# ---- 2. Placeholder for Isotonic Calibration ----\n",
    "class IsotonicCalibrator:\n",
    "    def __init__(self, num_tasks):\n",
    "        self.num_tasks = num_tasks\n",
    "        self.calibrators = [IsotonicRegression(out_of_bounds='clip') for _ in range(num_tasks)]\n",
    "\n",
    "    def fit(self, logits, targets):\n",
    "        for i in range(self.num_tasks):\n",
    "            self.calibrators[i].fit(logits[:, i], targets[:, i])\n",
    "\n",
    "    def predict(self, logits):\n",
    "        calibrated_probs = np.zeros_like(logits)\n",
    "        for i in range(self.num_tasks):\n",
    "            calibrated_probs[:, i] = self.calibrators[i].predict(logits[:, i])\n",
    "        return calibrated_probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fancy-rugby",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your data (adjust path as needed)\n",
    "df = pd.read_csv(\"/users/2/wan00232/ondemand/jupyter/ED_multitask/data/master_dataset_with_outcomes.csv\")\n",
    "col_list = [\n",
    "    \"age\", \"gender\", \"n_ed_30d\", \"n_ed_90d\", \"n_ed_365d\", \"n_hosp_30d\", \"n_hosp_90d\", \"n_hosp_365d\", \"n_icu_30d\", \"n_icu_90d\", \"n_icu_365d\", \"triage_temperature\", \"triage_heartrate\", \"triage_resprate\", \"triage_o2sat\", \"triage_sbp\", \"triage_dbp\", \"triage_pain\", \"triage_acuity\", \"chiefcom_chest_pain\", \"chiefcom_abdominal_pain\", \"chiefcom_headache\", \"chiefcom_shortness_of_breath\", \"chiefcom_back_pain\", \"chiefcom_cough\", \"chiefcom_nausea_vomiting\", \"chiefcom_fever_chills\", \"chiefcom_syncope\", \"chiefcom_dizziness\", \"cci_MI\", \"cci_CHF\", \"cci_PVD\", \"cci_Stroke\", \"cci_Dementia\", \"cci_Pulmonary\", \"cci_Rheumatic\", \"cci_PUD\", \"cci_Liver1\", \"cci_DM1\", \"cci_DM2\", \"cci_Paralysis\", \"cci_Renal\", \"cci_Cancer1\", \"cci_Liver2\", \"cci_Cancer2\", \"cci_HIV\", \"eci_Arrhythmia\", \"eci_Valvular\", \"eci_PHTN\",  \"eci_HTN1\", \"eci_HTN2\", \"eci_NeuroOther\", \"eci_Hypothyroid\", \"eci_Lymphoma\", \"eci_Coagulopathy\", \"eci_Obesity\", \"eci_WeightLoss\", \"eci_FluidsLytes\", \"eci_BloodLoss\", \"eci_Anemia\", \"eci_Alcohol\", \"eci_Drugs\",\"eci_Psychoses\", \"eci_Depression\"\n",
    "]\n",
    "outcome_list = [\n",
    "    \"outcome_hospitalization\", \"outcome_critical\", \"outcome_ed_revisit_3d\", \"outcome_sepsis\", \"outcome_pneumonia_bacterial\", \"outcome_pneumonia_viral\", \"outcome_pneumonia_all\", \"outcome_ards\", \"outcome_pe\", \"outcome_copd_exac\", \"outcome_acs_mi\", \"outcome_stroke\", \"outcome_aki\"\n",
    "]\n",
    "\n",
    "X_np = df.loc[:, col_list].select_dtypes(include=[np.number, bool]).fillna(0).to_numpy(dtype=float)\n",
    "\n",
    "# Model setup (match your training config)\n",
    "input_size = X_np.shape[1]\n",
    "num_experts = 8\n",
    "expert_hidden = [128, 64]\n",
    "expert_output_dim = 32\n",
    "tower_hidden_dim = 16\n",
    "task_output_dims = [1] * 13  # Adjust if needed\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = MMoE(input_size, num_experts, expert_hidden, expert_output_dim, tower_hidden_dim, task_output_dims).to(device)\n",
    "model.load_state_dict(torch.load(\"../best_mmoe_iso.pt\", map_location=device))\n",
    "model.eval()\n",
    "\n",
    "# Use a small background set for SHAP\n",
    "background = torch.from_numpy(X_np[:1000]).float().to(device)\n",
    "test_samples = torch.from_numpy(X_np[1000:1500]).float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "revised-rebel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Helper: Wrapper for expert/gate ---\n",
    "class ExpertWrapper(torch.nn.Module):\n",
    "    def __init__(self, expert):\n",
    "        super().__init__()\n",
    "        self.expert = expert\n",
    "    def forward(self, x):\n",
    "        return self.expert(x)\n",
    "\n",
    "class GateWrapper(torch.nn.Module):\n",
    "    def __init__(self, gate):\n",
    "        super().__init__()\n",
    "        self.gate = gate\n",
    "    def forward(self, x):\n",
    "        return torch.softmax(self.gate(x), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "directed-birthday",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SHAP for Experts:\n"
     ]
    }
   ],
   "source": [
    "# --- SHAP for Experts ---\n",
    "print(\"\\nSHAP for Experts:\")\n",
    "for i, expert in enumerate(model.experts):\n",
    "    expert_dir = f\"SHAP_Plot/expert_{i+1}\"\n",
    "    os.makedirs(expert_dir, exist_ok=True)\n",
    "    wrapper = ExpertWrapper(expert)\n",
    "    explainer = shap.DeepExplainer(wrapper, background)\n",
    "    shap_values = explainer.shap_values(test_samples)\n",
    "    if isinstance(shap_values, list):\n",
    "        shap_values = shap_values[0]\n",
    "    # shap_values shape: (batch, output_dim) or (batch, output_dim, input_dim)\n",
    "    # We want to aggregate over output_dim if present, to get (batch, input_dim)\n",
    "    if shap_values.ndim == 3:\n",
    "        # (batch, output_dim, input_dim) -> (batch, input_dim)\n",
    "        shap_values_input = np.mean(np.abs(shap_values), axis=1)\n",
    "    else:\n",
    "        shap_values_input = shap_values  # (batch, input_dim)\n",
    "    mean_abs_shap = np.abs(shap_values_input).mean(axis=0)\n",
    "    n_feat = min(20, mean_abs_shap.shape[0], X_np.shape[1])\n",
    "    top_idx = np.argsort(mean_abs_shap)[-n_feat:][::-1]\n",
    "    feature_names = np.array(col_list)[top_idx]\n",
    "    shap.summary_plot(shap_values_input[:, top_idx], X_np[1000:1500][:, top_idx], feature_names=feature_names, show=False)\n",
    "    plt.title(f\"Expert {i+1} Top {n_feat} Features\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(expert_dir, f\"expert_{i+1}_shap.png\"))\n",
    "    plt.close()\n",
    "    print(f\"Expert {i+1} SHAP plot saved to {expert_dir}\")\n",
    "\n",
    "# --- SHAP for Gates ---\n",
    "print(\"\\nSHAP for Gates:\")\n",
    "for t, gate in enumerate(model.gates):\n",
    "    gate_dir = f\"SHAP_Plot/gate_{t+1}\"\n",
    "    os.makedirs(gate_dir, exist_ok=True)\n",
    "    wrapper = GateWrapper(gate)\n",
    "    explainer = shap.DeepExplainer(wrapper, background)\n",
    "    shap_values = explainer.shap_values(test_samples, check_additivity=False)\n",
    "    if isinstance(shap_values, list):\n",
    "        shap_values = shap_values[0]\n",
    "    # shap_values shape: (batch, output_dim) or (batch, output_dim, input_dim)\n",
    "    if shap_values.ndim == 3:\n",
    "        shap_values_input = np.mean(np.abs(shap_values), axis=1)\n",
    "    else:\n",
    "        shap_values_input = shap_values\n",
    "    mean_abs_shap = np.abs(shap_values_input).mean(axis=0)\n",
    "    n_feat = min(20, mean_abs_shap.shape[0], X_np.shape[1])\n",
    "    top_idx = np.argsort(mean_abs_shap)[-n_feat:][::-1]\n",
    "    feature_names = np.array(col_list)[top_idx]\n",
    "    shap.summary_plot(shap_values_input[:, top_idx], X_np[1000:1500][:, top_idx], feature_names=feature_names, show=False)\n",
    "    plt.title(f\"Gate {t+1} Top {n_feat} Features\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(gate_dir, f\"gate_{t+1}_shap.png\"))\n",
    "    plt.close()\n",
    "    print(f\"Gate {t+1} SHAP plot saved to {gate_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "herbal-rental",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 py_ml_dl",
   "language": "python",
   "name": "py_ml_dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
